"""AG-UI åè®®å®¢æˆ·ç«¯

é€šè¿‡ AG-UI åè®®è°ƒç”¨ Knot å¹³å°ä¸Šçš„æ™ºèƒ½ä½“ã€‚
æ–‡æ¡£å‚è€ƒï¼šhttps://knot.woa.com/

æ”¯æŒåŠŸèƒ½ï¼š
- æµå¼/éæµå¼è°ƒç”¨
- å¤šç§äº‹ä»¶ç±»å‹å¤„ç†
- è‡ªåŠ¨é‡è¯•å’Œé”™è¯¯å¤„ç†
"""

import json
from datetime import datetime
from typing import Any, AsyncGenerator, Optional

import httpx
from loguru import logger

from src.config import settings


class AGUIClient:
    """AG-UI åè®®å®¢æˆ·ç«¯
    
    é€šè¿‡ AG-UI åè®®è°ƒç”¨ Knot å¹³å°æ™ºèƒ½ä½“ã€‚
    
    ä½¿ç”¨æ–¹å¼ï¼š
    1. ç”¨æˆ·ä¸ªäºº Token æ¨¡å¼ï¼ˆæ¨èï¼‰ï¼š
       - è®¾ç½® KNOT_API_TOKEN
       
    2. æ™ºèƒ½ä½“ Token æ¨¡å¼ï¼š
       - è®¾ç½® KNOT_AGENT_TOKEN å’Œ KNOT_USERNAME
    """
    
    # API ç«¯ç‚¹æ¨¡æ¿
    API_URL_TEMPLATE = "http://knot.woa.com/apigw/api/v1/agents/agui/{agent_id}"
    
    # é»˜è®¤è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    DEFAULT_TIMEOUT = 120
    
    # æ”¯æŒçš„æ¨¡å‹
    SUPPORTED_MODELS = ["deepseek-v3.1", "deepseek-v3.2", "glm-4.7"]
    
    def __init__(
        self,
        agent_id: Optional[str] = None,
        api_token: Optional[str] = None,
        agent_token: Optional[str] = None,
        username: Optional[str] = None,
        model: Optional[str] = None,
        timeout: int = DEFAULT_TIMEOUT,
    ):
        """åˆå§‹åŒ– AG-UI å®¢æˆ·ç«¯
        
        Args:
            agent_id: æ™ºèƒ½ä½“ ID
            api_token: ç”¨æˆ·ä¸ªäºº Tokenï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
            agent_token: æ™ºèƒ½ä½“ Token
            username: ç”¨æˆ·åï¼ˆä½¿ç”¨æ™ºèƒ½ä½“ Token æ—¶éœ€è¦ï¼‰
            model: æ¨¡å‹åç§°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.agent_id = agent_id or settings.knot_agent_id
        self.api_token = api_token or settings.knot_api_token
        self.agent_token = agent_token or settings.knot_agent_token
        self.username = username or settings.knot_username
        self.model = model or settings.knot_model
        self.timeout = timeout
        
        # éªŒè¯é…ç½®
        if not self.agent_id:
            raise ValueError("Agent ID is required (KNOT_AGENT_ID)")
        
        if not self.api_token and not self.agent_token:
            raise ValueError(
                "Either API Token (KNOT_API_TOKEN) or "
                "Agent Token (KNOT_AGENT_TOKEN) is required"
            )
        
        if self.agent_token and not self.username:
            raise ValueError(
                "Username (KNOT_USERNAME) is required when using Agent Token"
            )
        
        # æ„å»º API URL
        self.api_url = self.API_URL_TEMPLATE.format(agent_id=self.agent_id)
        
        logger.info(
            f"AGUIClient initialized: agent_id={self.agent_id}, "
            f"model={self.model}, auth_mode={'api_token' if self.api_token else 'agent_token'}"
        )
    
    def _build_headers(self) -> dict[str, str]:
        """æ„å»ºè¯·æ±‚å¤´"""
        if self.api_token:
            # ç”¨æˆ·ä¸ªäºº Token æ¨¡å¼
            return {
                "x-knot-api-token": self.api_token,
                "Content-Type": "application/json",
            }
        else:
            # æ™ºèƒ½ä½“ Token æ¨¡å¼
            return {
                "x-knot-token": self.agent_token,
                "X-Username": self.username,
                "Content-Type": "application/json",
            }
    
    def _build_request_body(
        self,
        message: str,
        conversation_id: str = "",
        stream: bool = True,
        enable_web_search: bool = False,
        temperature: float = 0.5,
        attached_images: Optional[list[str]] = None,
        extra_headers: Optional[dict[str, str]] = None,
    ) -> dict[str, Any]:
        """æ„å»ºè¯·æ±‚ä½“
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_id: ä¼šè¯ IDï¼ˆç•™ç©ºåˆ›å»ºæ–°ä¼šè¯ï¼‰
            stream: æ˜¯å¦æµå¼è¿”å›
            enable_web_search: æ˜¯å¦å¼€å¯è”ç½‘æœç´¢
            temperature: æ¸©åº¦å‚æ•° [0, 1]
            attached_images: é™„åŠ å›¾ç‰‡ URL åˆ—è¡¨
            extra_headers: é¢å¤–è¯·æ±‚å¤´ï¼ˆé€ä¼ ç»™ MCP å·¥å…·ï¼‰
        """
        body = {
            "input": {
                "message": message,
                "conversation_id": conversation_id,
                "model": self.model,
                "stream": stream,
                "enable_web_search": enable_web_search,
                "temperature": temperature,
                "chat_extra": {
                    "attached_images": attached_images or [],
                    "extra_headers": extra_headers or {},
                },
            }
        }
        return body
    
    async def chat(
        self,
        message: str,
        conversation_id: str = "",
        stream: bool = False,
        enable_web_search: bool = False,
        temperature: float = 0.5,
    ) -> dict[str, Any]:
        """å‘é€æ¶ˆæ¯å¹¶è·å–å®Œæ•´å“åº”ï¼ˆéæµå¼ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_id: ä¼šè¯ ID
            stream: æ˜¯å¦æµå¼ï¼ˆæ­¤æ–¹æ³•å†…éƒ¨å¤„ç†æµå¼ï¼Œè¿”å›å®Œæ•´ç»“æœï¼‰
            enable_web_search: æ˜¯å¦å¼€å¯è”ç½‘æœç´¢
            temperature: æ¸©åº¦å‚æ•°
            
        Returns:
            åŒ…å«å®Œæ•´å“åº”çš„å­—å…¸ï¼š
            {
                "content": "å®Œæ•´å“åº”å†…å®¹",
                "conversation_id": "ä¼šè¯ID",
                "message_id": "æ¶ˆæ¯ID",
                "thinking": "æ€è€ƒè¿‡ç¨‹ï¼ˆå¦‚æœ‰ï¼‰",
                "tool_calls": [...],  # å·¥å…·è°ƒç”¨è®°å½•
                "token_usage": {...},  # Token ä½¿ç”¨æƒ…å†µ
                "error": None,  # é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
            }
        """
        headers = self._build_headers()
        body = self._build_request_body(
            message=message,
            conversation_id=conversation_id,
            stream=True,  # ä½¿ç”¨æµå¼è·å–ï¼Œå†…éƒ¨å¤„ç†
            enable_web_search=enable_web_search,
            temperature=temperature,
        )
        
        result = {
            "content": "",
            "conversation_id": "",
            "message_id": "",
            "thinking": "",
            "tool_calls": [],
            "token_usage": None,
            "error": None,
        }
        
        content_parts = []
        thinking_parts = []
        
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                async with client.stream(
                    "POST",
                    self.api_url,
                    json=body,
                    headers=headers,
                ) as response:
                    if response.status_code != 200:
                        error_text = await response.aread()
                        result["error"] = f"HTTP {response.status_code}: {error_text.decode()}"
                        logger.error(f"AGUI request failed: {result['error']}")
                        return result
                    
                    async for line in response.aiter_lines():
                        if not line:
                            continue
                        
                        # å¤„ç† SSE æ ¼å¼
                        chunk_str = line.lstrip("data:").strip()
                        if chunk_str == "[DONE]":
                            break
                        
                        try:
                            msg = json.loads(chunk_str)
                        except json.JSONDecodeError:
                            continue
                        
                        if "type" not in msg:
                            continue
                        
                        msg_type = msg["type"]
                        raw_event = msg.get("rawEvent", {})
                        
                        # æ›´æ–°ä¼šè¯ä¿¡æ¯
                        if "conversation_id" in raw_event:
                            result["conversation_id"] = raw_event["conversation_id"]
                        if "message_id" in raw_event:
                            result["message_id"] = raw_event["message_id"]
                        
                        # å¤„ç†ä¸åŒäº‹ä»¶ç±»å‹
                        if msg_type == "TEXT_MESSAGE_CONTENT":
                            content_parts.append(raw_event.get("content", ""))
                        
                        elif msg_type == "THINKING_TEXT_MESSAGE_CONTENT":
                            thinking_parts.append(raw_event.get("content", ""))
                        
                        elif msg_type == "TOOL_CALL_START":
                            result["tool_calls"].append({
                                "name": raw_event.get("name"),
                                "status": "started",
                            })
                        
                        elif msg_type == "TOOL_CALL_RESULT":
                            if result["tool_calls"]:
                                result["tool_calls"][-1]["status"] = "completed"
                                result["tool_calls"][-1]["result"] = raw_event.get("result")
                        
                        elif msg_type == "STEP_FINISHED":
                            if "token_usage" in raw_event:
                                result["token_usage"] = raw_event["token_usage"]
                        
                        elif msg_type == "RUN_ERROR":
                            tip_option = raw_event.get("tip_option", {})
                            result["error"] = tip_option.get("content", "Unknown error")
                            logger.error(f"AGUI run error: {result['error']}")
            
            result["content"] = "".join(content_parts)
            result["thinking"] = "".join(thinking_parts)
            
            logger.info(
                f"AGUI chat completed: conversation_id={result['conversation_id']}, "
                f"content_length={len(result['content'])}"
            )
            
        except httpx.TimeoutException:
            result["error"] = f"Request timeout after {self.timeout}s"
            logger.error(result["error"])
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"AGUI request exception: {e}")
        
        return result
    
    async def chat_stream(
        self,
        message: str,
        conversation_id: str = "",
        enable_web_search: bool = False,
        temperature: float = 0.5,
    ) -> AsyncGenerator[dict[str, Any], None]:
        """æµå¼å‘é€æ¶ˆæ¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            conversation_id: ä¼šè¯ ID
            enable_web_search: æ˜¯å¦å¼€å¯è”ç½‘æœç´¢
            temperature: æ¸©åº¦å‚æ•°
            
        Yields:
            äº‹ä»¶å­—å…¸ï¼š
            {
                "type": "äº‹ä»¶ç±»å‹",
                "content": "å†…å®¹ï¼ˆå¦‚æœ‰ï¼‰",
                "raw_event": {...},
            }
        """
        headers = self._build_headers()
        body = self._build_request_body(
            message=message,
            conversation_id=conversation_id,
            stream=True,
            enable_web_search=enable_web_search,
            temperature=temperature,
        )
        
        try:
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                async with client.stream(
                    "POST",
                    self.api_url,
                    json=body,
                    headers=headers,
                ) as response:
                    if response.status_code != 200:
                        error_text = await response.aread()
                        yield {
                            "type": "ERROR",
                            "content": f"HTTP {response.status_code}: {error_text.decode()}",
                            "raw_event": {},
                        }
                        return
                    
                    async for line in response.aiter_lines():
                        if not line:
                            continue
                        
                        chunk_str = line.lstrip("data:").strip()
                        if chunk_str == "[DONE]":
                            yield {"type": "DONE", "content": "", "raw_event": {}}
                            break
                        
                        try:
                            msg = json.loads(chunk_str)
                        except json.JSONDecodeError:
                            continue
                        
                        if "type" not in msg:
                            continue
                        
                        yield {
                            "type": msg["type"],
                            "content": msg.get("rawEvent", {}).get("content", ""),
                            "raw_event": msg.get("rawEvent", {}),
                        }
        
        except httpx.TimeoutException:
            yield {
                "type": "ERROR",
                "content": f"Request timeout after {self.timeout}s",
                "raw_event": {},
            }
        except Exception as e:
            yield {
                "type": "ERROR",
                "content": str(e),
                "raw_event": {},
            }


class TrumpPostAnalyzer:
    """Trump å¸–å­åˆ†æå™¨
    
    å°è£… AG-UI å®¢æˆ·ç«¯ï¼Œä¸“é—¨ç”¨äºè°ƒç”¨ Trump è¨€è®ºåˆ†æ Agentã€‚
    """
    
    def __init__(self, agui_client: Optional[AGUIClient] = None):
        """åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            agui_client: AG-UI å®¢æˆ·ç«¯å®ä¾‹ï¼ˆå¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨åˆ›å»ºï¼‰
        """
        self.client = agui_client
        self._initialized = False
    
    def _ensure_client(self) -> bool:
        """ç¡®ä¿å®¢æˆ·ç«¯å·²åˆå§‹åŒ–"""
        if self._initialized:
            return self.client is not None
        
        self._initialized = True
        
        if self.client:
            return True
        
        # æ£€æŸ¥é…ç½®
        if not settings.knot_agent_id:
            logger.warning("Trump Post Analyzer disabled: KNOT_AGENT_ID not configured")
            return False
        
        if not settings.knot_api_token and not settings.knot_agent_token:
            logger.warning(
                "Trump Post Analyzer disabled: "
                "KNOT_API_TOKEN or KNOT_AGENT_TOKEN not configured"
            )
            return False
        
        try:
            self.client = AGUIClient()
            logger.info("Trump Post Analyzer initialized successfully")
            return True
        except Exception as e:
            logger.error(f"Failed to initialize Trump Post Analyzer: {e}")
            return False
    
    def _build_analysis_prompt(
        self,
        content: str,
        translated_content: Optional[str] = None,
        posted_at: Optional[datetime] = None,
        context: Optional[str] = None,
    ) -> str:
        """æ„å»ºåˆ†æ Prompt
        
        Args:
            content: å¸–å­åŸæ–‡ï¼ˆè‹±æ–‡ï¼‰
            translated_content: ç¿»è¯‘å†…å®¹ï¼ˆä¸­æ–‡ï¼‰
            posted_at: å‘å¸ƒæ—¶é—´
            context: è¡¥å……èƒŒæ™¯ä¿¡æ¯
        """
        # æ„å»ºè¾“å…¥ JSON
        input_data = {
            "content": content,
        }
        
        if translated_content:
            input_data["translated_content"] = translated_content
        
        if posted_at:
            input_data["posted_at"] = posted_at.isoformat()
        
        if context:
            input_data["context"] = context
        
        prompt = f"""è¯·åˆ†æä»¥ä¸‹ Trump å¸–å­ï¼š

```json
{json.dumps(input_data, ensure_ascii=False, indent=2)}
```

è¯·æŒ‰ç…§ä½ çš„åˆ†ææ¡†æ¶ï¼Œè¾“å‡ºå®Œæ•´çš„ JSON æ ¼å¼åˆ†ææŠ¥å‘Šã€‚"""
        
        return prompt
    
    async def analyze_post(
        self,
        content: str,
        translated_content: Optional[str] = None,
        posted_at: Optional[datetime] = None,
        context: Optional[str] = None,
    ) -> dict[str, Any]:
        """åˆ†æå•æ¡å¸–å­
        
        Args:
            content: å¸–å­åŸæ–‡
            translated_content: ç¿»è¯‘å†…å®¹
            posted_at: å‘å¸ƒæ—¶é—´
            context: è¡¥å……èƒŒæ™¯
            
        Returns:
            åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
            - status: "success" | "error" | "disabled"
            - analysis: åˆ†æç»“æœï¼ˆJSON è§£æåçš„å­—å…¸ï¼‰
            - raw_content: åŸå§‹å“åº”å†…å®¹
            - error: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰
            - analyzed_at: åˆ†ææ—¶é—´
        """
        result = {
            "status": "disabled",
            "analysis": None,
            "raw_content": "",
            "error": None,
            "analyzed_at": datetime.now().isoformat(),
        }
        
        if not self._ensure_client():
            result["error"] = "Analyzer not configured"
            return result
        
        try:
            prompt = self._build_analysis_prompt(
                content=content,
                translated_content=translated_content,
                posted_at=posted_at,
                context=context,
            )
            
            response = await self.client.chat(
                message=prompt,
                temperature=0.3,  # ä½æ¸©åº¦ï¼Œä¿è¯è¾“å‡ºç¨³å®š
            )
            
            if response["error"]:
                result["status"] = "error"
                result["error"] = response["error"]
                return result
            
            raw_content = response["content"]
            result["raw_content"] = raw_content
            
            # å°è¯•è§£æ JSON
            analysis = self._extract_json(raw_content)
            if analysis:
                result["status"] = "success"
                result["analysis"] = analysis
            else:
                # JSON è§£æå¤±è´¥ï¼Œä½†æœ‰å†…å®¹
                result["status"] = "success"
                result["analysis"] = {"raw_response": raw_content}
                logger.warning("Failed to parse JSON from analysis response")
            
            logger.info(f"Post analysis completed: status={result['status']}")
            
        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)
            logger.error(f"Post analysis failed: {e}")
        
        return result
    
    async def analyze_batch(
        self,
        posts: list[dict],
        analysis_focus: Optional[str] = None,
    ) -> dict[str, Any]:
        """æ‰¹é‡åˆ†æå¸–å­
        
        Args:
            posts: å¸–å­åˆ—è¡¨ï¼Œæ¯ä¸ªå¸–å­åŒ…å« content, translated_content, posted_at
            analysis_focus: åˆ†æé‡ç‚¹ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            æ‰¹é‡åˆ†æç»“æœ
        """
        result = {
            "status": "disabled",
            "analysis": None,
            "raw_content": "",
            "error": None,
            "analyzed_at": datetime.now().isoformat(),
        }
        
        if not self._ensure_client():
            result["error"] = "Analyzer not configured"
            return result
        
        try:
            # æ„å»ºæ‰¹é‡åˆ†æ Prompt
            input_data = {
                "posts": posts,
            }
            if analysis_focus:
                input_data["analysis_focus"] = analysis_focus
            
            prompt = f"""è¯·æ‰¹é‡åˆ†æä»¥ä¸‹ Trump å¸–å­ï¼š

```json
{json.dumps(input_data, ensure_ascii=False, indent=2)}
```

è¯·ç»¼åˆåˆ†æè¿™äº›å¸–å­çš„æ•´ä½“è¶‹åŠ¿å’Œå½±å“ï¼Œè¾“å‡ºå®Œæ•´çš„ JSON æ ¼å¼åˆ†ææŠ¥å‘Šã€‚"""
            
            response = await self.client.chat(
                message=prompt,
                temperature=0.3,
            )
            
            if response["error"]:
                result["status"] = "error"
                result["error"] = response["error"]
                return result
            
            raw_content = response["content"]
            result["raw_content"] = raw_content
            
            analysis = self._extract_json(raw_content)
            if analysis:
                result["status"] = "success"
                result["analysis"] = analysis
            else:
                result["status"] = "success"
                result["analysis"] = {"raw_response": raw_content}
            
        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)
            logger.error(f"Batch analysis failed: {e}")
        
        return result
    
    def _extract_json(self, text: str) -> Optional[dict]:
        """ä»æ–‡æœ¬ä¸­æå– JSON
        
        æ”¯æŒï¼š
        - çº¯ JSON æ–‡æœ¬
        - Markdown ä»£ç å—åŒ…è£¹çš„ JSON
        """
        if not text:
            return None
        
        # å°è¯•ç›´æ¥è§£æ
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            pass
        
        # å°è¯•æå– ```json ... ``` ä»£ç å—
        import re
        json_pattern = r'```(?:json)?\s*([\s\S]*?)\s*```'
        matches = re.findall(json_pattern, text)
        
        for match in matches:
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue
        
        # å°è¯•æå– { ... } å—
        brace_pattern = r'\{[\s\S]*\}'
        matches = re.findall(brace_pattern, text)
        
        for match in matches:
            try:
                return json.loads(match)
            except json.JSONDecodeError:
                continue
        
        return None
    
    def format_analysis_for_feishu(self, analysis: dict) -> str:
        """å°†åˆ†æç»“æœæ ¼å¼åŒ–ä¸ºé£ä¹¦æ¶ˆæ¯
        
        Args:
            analysis: åˆ†æç»“æœå­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„ Markdown æ–‡æœ¬
        """
        if not analysis:
            return "âš ï¸ åˆ†æç»“æœä¸ºç©º"
        
        lines = []
        
        # æ ¸å¿ƒç»“è®º
        summary = analysis.get("summary", {})
        if summary:
            lines.append("ğŸ“Š **AI åˆ†ææ‘˜è¦**")
            lines.append("")
            if headline := summary.get("headline"):
                lines.append(f"**{headline}**")
            
            sentiment = summary.get("overall_sentiment", "")
            sentiment_emoji = {
                "bullish": "ğŸ“ˆ",
                "bearish": "ğŸ“‰",
                "neutral": "â¡ï¸",
                "mixed": "â†”ï¸",
            }.get(sentiment, "")
            
            impact = summary.get("market_impact_level", "")
            impact_emoji = {
                "high": "ğŸ”´",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢",
            }.get(impact, "")
            
            if sentiment or impact:
                lines.append(f"{sentiment_emoji} æƒ…ç»ª: {sentiment} | {impact_emoji} å½±å“: {impact}")
            lines.append("")
        
        # æŠ•èµ„å»ºè®®
        recommendations = analysis.get("investment_recommendations", [])
        if recommendations:
            lines.append("ğŸ’¡ **æŠ•èµ„å»ºè®®**")
            lines.append("")
            for rec in recommendations[:3]:  # æœ€å¤šæ˜¾ç¤º 3 æ¡
                category = rec.get("category", "")
                direction = rec.get("direction", "")
                confidence = rec.get("confidence", 0)
                
                direction_emoji = {
                    "long": "ğŸ“ˆ",
                    "short": "ğŸ“‰",
                    "hedge": "ğŸ›¡ï¸",
                }.get(direction, "")
                
                lines.append(f"{direction_emoji} **{category}** (ç½®ä¿¡åº¦: {confidence}%)")
                
                targets = rec.get("specific_targets", [])
                for target in targets[:2]:  # æ¯ç±»æœ€å¤š 2 ä¸ªæ ‡çš„
                    name = target.get("name", "")
                    rationale = target.get("rationale", "")
                    lines.append(f"  â€¢ {name}: {rationale}")
                lines.append("")
        
        # é£é™©æç¤º
        warnings = analysis.get("risk_warnings", [])
        if warnings:
            lines.append("âš ï¸ **é£é™©æç¤º**")
            for w in warnings[:3]:
                lines.append(f"â€¢ {w}")
            lines.append("")
        
        # åç»­å…³æ³¨
        follow_up = analysis.get("follow_up_signals", [])
        if follow_up:
            lines.append("ğŸ‘€ **åç»­å…³æ³¨**")
            for f in follow_up[:3]:
                lines.append(f"â€¢ {f}")
        
        return "\n".join(lines)


# å…¨å±€å®ä¾‹
_trump_analyzer: Optional[TrumpPostAnalyzer] = None


def get_trump_analyzer() -> TrumpPostAnalyzer:
    """è·å– Trump å¸–å­åˆ†æå™¨å•ä¾‹"""
    global _trump_analyzer
    if _trump_analyzer is None:
        _trump_analyzer = TrumpPostAnalyzer()
    return _trump_analyzer
